{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gjduart/Graph-Learning/blob/main/Simplifiying_Graph_Convolutional_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2GvQkARxmjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11a8f53-c7e6-47d2-d12f-e655385810a6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  9 18:09:55 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WhbMm1BZfcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c44317f-758a-4d1d-a663-3bb3178e16e3"
      },
      "source": [
        "\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.9.0+cu111.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.9.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 29.7 MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.9.0%2Bcu111/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (870 kB)\n",
            "\u001b[K     |████████████████████████████████| 870 kB 39.0 MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.2.tar.gz (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.0.2-py3-none-any.whl (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 31.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.2-py3-none-any.whl size=535570 sha256=cd3652c1cd4c3541545d3b49d05c4ed51bcf532187ff527e7f1ee96bc550e75a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/08/13/2321517088bb2e95bfd0e45033bb9c923189e5b2078e0be4ef\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-spline-conv, torch-sparse, torch-scatter, torch-geometric, torch-cluster\n",
            "Successfully installed isodate-0.6.0 rdflib-6.0.2 torch-cluster-1.5.9 torch-geometric-2.0.2 torch-scatter-2.0.9 torch-sparse-0.6.12 torch-spline-conv-1.2.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-hS6SQ2f2mS"
      },
      "source": [
        "import math \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "import time\n",
        "from time import perf_counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUH6dz7ofAu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a46db5a-30e8-480d-dccf-d5a5ef3a6281"
      },
      "source": [
        "#torch.random.manual_seed(42) #fixando uma seed\n",
        "\n",
        "torch.manual_seed(126) \n",
        "torch.random.manual_seed(126)\n",
        "torch.cuda.manual_seed(126)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6zOgtv6ZkcL"
      },
      "source": [
        "\n",
        "def load_data_planetoid(nome):\n",
        "    dataset = Planetoid(root='/tmp/Planetoid', name=nome).shuffle()\n",
        "    dataset = dataset[0]\n",
        "    data = dataset.to(device)\n",
        "    \n",
        "    features = data.x\n",
        "    labels = data.y \n",
        "    train_mask = data.train_mask\n",
        "    print(train_mask.shape) \n",
        "    val_mask = data.val_mask\n",
        "    test_mask = data.test_mask\n",
        "    adj = pyg_utils.to_dense_adj(data.edge_index)\n",
        "    adj = adj.reshape(features.shape[0],features.shape[0])\n",
        "    print(f'Features Shape:{features.shape}')\n",
        "    print(f'labels shape:  {labels.shape}')\n",
        "    print(f'Adjacency shape:{adj.shape}')\n",
        "\n",
        "\n",
        "    return adj,features, labels, train_mask, val_mask, test_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bomHWwLhcLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3879cde4-80d8-4b21-f254-dc9318e173ee"
      },
      "source": [
        "adj, features, labels, idx_train, idx_val, idx_test = load_data_planetoid('cora')\n",
        "adj = adj + torch.eye(adj.shape[0]).to(device)  # Add self-loops\n",
        "adj"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2708])\n",
            "Features Shape:torch.Size([2708, 1433])\n",
            "labels shape:  torch.Size([2708])\n",
            "Adjacency shape:torch.Size([2708, 2708])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 1., 1.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqyuhAxX7cGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1dc19b-c29c-4326-d05d-5faa7ab81915"
      },
      "source": [
        "idx_train.sum(), idx_val.sum(), idx_test.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(140, device='cuda:0'),\n",
              " tensor(500, device='cuda:0'),\n",
              " tensor(1000, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohiqDmbBXmV3"
      },
      "source": [
        "\n",
        "class SGC(nn.Module):\n",
        "    def __init__(self, k, nfeat, nclass):\n",
        "        super(SGC, self).__init__()\n",
        "        self.k = k\n",
        "        self.W = nn.Linear(nfeat, nclass, bias=True)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        k = self.k\n",
        "        for i in range(k):\n",
        "            x = torch.spmm(adj, x) #Sparce matrix mutplic...\n",
        "        x = self.W(x)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9valV05mCnf"
      },
      "source": [
        "\n",
        "# def train():\n",
        "    \n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "#     loss= criterion(model()[data.train_mask], data.y[data.train_mask])\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "def train(features,edge_index, model, opt,labels):\n",
        "    model.train()\n",
        "    opt.zero_grad()\n",
        "    output = model(features, edge_index)\n",
        "    loss = nn.functional.cross_entropy(output[idx_train], labels[idx_train])\n",
        "\n",
        "    #loss = nn.functional.multi_margin_loss(input=output[idx_train], target=labels[idx_train],reduction='mean')\n",
        "\n",
        "\n",
        "   \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDmI-R7JpvXH"
      },
      "source": [
        "def accuracy(output, labels):\n",
        "    \n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    #print(preds.shape)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBfnKymXnxf5"
      },
      "source": [
        "@torch.no_grad()\n",
        "def test(features,adj, model,mask):\n",
        "  \n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    output = model(features, adj)\n",
        "    return accuracy(output[mask], labels[mask])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3_se_OMX1EN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33453526-7da0-41ba-94ef-7e3ba0373a88"
      },
      "source": [
        "\n",
        "epochs = 100\n",
        "k = 2\n",
        "lr = 0.2\n",
        "wd = 0.000001\n",
        "\n",
        "\n",
        "acc_total_test = []\n",
        "acc_total_train = []\n",
        "\n",
        "#Modelo\n",
        "\n",
        "# Treinamento\n",
        "iterations = 1\n",
        "loss= []\n",
        "for i in range(iterations):\n",
        "    start_all_time = time.time()\n",
        "    model = SGC(k, features.size()[1], int(labels.max().item()+1))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
        "                              weight_decay=wd)\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "          time_per_epoch =  time.time()\n",
        "          train_loss = train(features,adj, model, optimizer,labels)\n",
        "          loss.append(train_loss)\n",
        "          train_acc = test(features,adj, model,idx_train)\n",
        "          test_acc = test(features,adj, model, idx_test)\n",
        "\n",
        "          print(f'=============iteracao{i}==================================')\n",
        "          print('Epoch: {:03d}, Train Loss: {:.9f}, Train Acc: {:.7f}, Test Acc: {:.7f}, Time:{:.3f}'.format(epoch, train_loss, train_acc, test_acc, time.time()-time_per_epoch))\n",
        "          if epoch==99:\n",
        "            acc_total_test.append(test_acc)\n",
        "            acc_total_train.append(train_acc)\n",
        "    print(f'Tempo total:{time.time() - start_all_time:.3f}')      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============iteracao0==================================\n",
            "Epoch: 000, Train Loss: 3.447897196, Train Acc: 0.6071429, Test Acc: 0.5670000, Time:0.071\n",
            "=============iteracao0==================================\n",
            "Epoch: 001, Train Loss: 49.332828522, Train Acc: 0.5142857, Test Acc: 0.3650000, Time:0.072\n",
            "=============iteracao0==================================\n",
            "Epoch: 002, Train Loss: 70.257133484, Train Acc: 0.6642857, Test Acc: 0.4980000, Time:0.070\n",
            "=============iteracao0==================================\n",
            "Epoch: 003, Train Loss: 41.183200836, Train Acc: 0.7571429, Test Acc: 0.6080000, Time:0.064\n",
            "=============iteracao0==================================\n",
            "Epoch: 004, Train Loss: 29.445594788, Train Acc: 0.7857143, Test Acc: 0.6410000, Time:0.066\n",
            "=============iteracao0==================================\n",
            "Epoch: 005, Train Loss: 23.875240326, Train Acc: 0.8571429, Test Acc: 0.6870000, Time:0.060\n",
            "=============iteracao0==================================\n",
            "Epoch: 006, Train Loss: 18.446193695, Train Acc: 0.8785714, Test Acc: 0.6800000, Time:0.060\n",
            "=============iteracao0==================================\n",
            "Epoch: 007, Train Loss: 18.816898346, Train Acc: 0.8928571, Test Acc: 0.6820000, Time:0.058\n",
            "=============iteracao0==================================\n",
            "Epoch: 008, Train Loss: 13.543411255, Train Acc: 0.9285714, Test Acc: 0.7190000, Time:0.054\n",
            "=============iteracao0==================================\n",
            "Epoch: 009, Train Loss: 6.327392578, Train Acc: 0.9571429, Test Acc: 0.7470000, Time:0.054\n",
            "=============iteracao0==================================\n",
            "Epoch: 010, Train Loss: 2.752055168, Train Acc: 0.9714286, Test Acc: 0.7550000, Time:0.055\n",
            "=============iteracao0==================================\n",
            "Epoch: 011, Train Loss: 1.192840695, Train Acc: 0.9714286, Test Acc: 0.7570000, Time:0.051\n",
            "=============iteracao0==================================\n",
            "Epoch: 012, Train Loss: 0.250896484, Train Acc: 0.9928571, Test Acc: 0.7600000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 013, Train Loss: 0.136147261, Train Acc: 0.9928571, Test Acc: 0.7560000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 014, Train Loss: 0.094030648, Train Acc: 0.9785714, Test Acc: 0.7590000, Time:0.051\n",
            "=============iteracao0==================================\n",
            "Epoch: 015, Train Loss: 0.323980898, Train Acc: 0.9857143, Test Acc: 0.7580000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 016, Train Loss: 0.102360606, Train Acc: 1.0000000, Test Acc: 0.7620000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 017, Train Loss: 0.000001815, Train Acc: 1.0000000, Test Acc: 0.7560000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 018, Train Loss: 0.000000677, Train Acc: 1.0000000, Test Acc: 0.7510000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 019, Train Loss: 0.000000687, Train Acc: 1.0000000, Test Acc: 0.7500000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 020, Train Loss: 0.000000768, Train Acc: 1.0000000, Test Acc: 0.7480000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 021, Train Loss: 0.000000891, Train Acc: 1.0000000, Test Acc: 0.7470000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 022, Train Loss: 0.000001041, Train Acc: 1.0000000, Test Acc: 0.7440000, Time:0.047\n",
            "=============iteracao0==================================\n",
            "Epoch: 023, Train Loss: 0.000001213, Train Acc: 1.0000000, Test Acc: 0.7440000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 024, Train Loss: 0.000001403, Train Acc: 1.0000000, Test Acc: 0.7390000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 025, Train Loss: 0.000001606, Train Acc: 1.0000000, Test Acc: 0.7350000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 026, Train Loss: 0.000001818, Train Acc: 1.0000000, Test Acc: 0.7360000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 027, Train Loss: 0.000002036, Train Acc: 1.0000000, Test Acc: 0.7340000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 028, Train Loss: 0.000002257, Train Acc: 1.0000000, Test Acc: 0.7310000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 029, Train Loss: 0.000002481, Train Acc: 1.0000000, Test Acc: 0.7260000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 030, Train Loss: 0.000002704, Train Acc: 1.0000000, Test Acc: 0.7260000, Time:0.052\n",
            "=============iteracao0==================================\n",
            "Epoch: 031, Train Loss: 0.000002921, Train Acc: 1.0000000, Test Acc: 0.7260000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 032, Train Loss: 0.000003135, Train Acc: 1.0000000, Test Acc: 0.7250000, Time:0.052\n",
            "=============iteracao0==================================\n",
            "Epoch: 033, Train Loss: 0.000003340, Train Acc: 1.0000000, Test Acc: 0.7230000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 034, Train Loss: 0.000003535, Train Acc: 1.0000000, Test Acc: 0.7250000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 035, Train Loss: 0.000003723, Train Acc: 1.0000000, Test Acc: 0.7260000, Time:0.047\n",
            "=============iteracao0==================================\n",
            "Epoch: 036, Train Loss: 0.000003897, Train Acc: 1.0000000, Test Acc: 0.7260000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 037, Train Loss: 0.000004061, Train Acc: 1.0000000, Test Acc: 0.7250000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 038, Train Loss: 0.000004213, Train Acc: 1.0000000, Test Acc: 0.7250000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 039, Train Loss: 0.000004352, Train Acc: 1.0000000, Test Acc: 0.7230000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 040, Train Loss: 0.000004477, Train Acc: 1.0000000, Test Acc: 0.7230000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 041, Train Loss: 0.000004590, Train Acc: 1.0000000, Test Acc: 0.7230000, Time:0.047\n",
            "=============iteracao0==================================\n",
            "Epoch: 042, Train Loss: 0.000004689, Train Acc: 1.0000000, Test Acc: 0.7230000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 043, Train Loss: 0.000004777, Train Acc: 1.0000000, Test Acc: 0.7210000, Time:0.047\n",
            "=============iteracao0==================================\n",
            "Epoch: 044, Train Loss: 0.000004853, Train Acc: 1.0000000, Test Acc: 0.7190000, Time:0.052\n",
            "=============iteracao0==================================\n",
            "Epoch: 045, Train Loss: 0.000004917, Train Acc: 1.0000000, Test Acc: 0.7190000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 046, Train Loss: 0.000004971, Train Acc: 1.0000000, Test Acc: 0.7190000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 047, Train Loss: 0.000005014, Train Acc: 1.0000000, Test Acc: 0.7190000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 048, Train Loss: 0.000005046, Train Acc: 1.0000000, Test Acc: 0.7190000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 049, Train Loss: 0.000005071, Train Acc: 1.0000000, Test Acc: 0.7190000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 050, Train Loss: 0.000005085, Train Acc: 1.0000000, Test Acc: 0.7180000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 051, Train Loss: 0.000005093, Train Acc: 1.0000000, Test Acc: 0.7180000, Time:0.047\n",
            "=============iteracao0==================================\n",
            "Epoch: 052, Train Loss: 0.000005092, Train Acc: 1.0000000, Test Acc: 0.7180000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 053, Train Loss: 0.000005085, Train Acc: 1.0000000, Test Acc: 0.7180000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 054, Train Loss: 0.000005071, Train Acc: 1.0000000, Test Acc: 0.7180000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 055, Train Loss: 0.000005052, Train Acc: 1.0000000, Test Acc: 0.7180000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 056, Train Loss: 0.000005029, Train Acc: 1.0000000, Test Acc: 0.7180000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 057, Train Loss: 0.000004999, Train Acc: 1.0000000, Test Acc: 0.7180000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 058, Train Loss: 0.000004967, Train Acc: 1.0000000, Test Acc: 0.7170000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 059, Train Loss: 0.000004931, Train Acc: 1.0000000, Test Acc: 0.7170000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 060, Train Loss: 0.000004893, Train Acc: 1.0000000, Test Acc: 0.7170000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 061, Train Loss: 0.000004850, Train Acc: 1.0000000, Test Acc: 0.7170000, Time:0.047\n",
            "=============iteracao0==================================\n",
            "Epoch: 062, Train Loss: 0.000004805, Train Acc: 1.0000000, Test Acc: 0.7170000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 063, Train Loss: 0.000004759, Train Acc: 1.0000000, Test Acc: 0.7170000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 064, Train Loss: 0.000004711, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 065, Train Loss: 0.000004661, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 066, Train Loss: 0.000004612, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 067, Train Loss: 0.000004560, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 068, Train Loss: 0.000004507, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 069, Train Loss: 0.000004455, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 070, Train Loss: 0.000004401, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 071, Train Loss: 0.000004348, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 072, Train Loss: 0.000004295, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.047\n",
            "=============iteracao0==================================\n",
            "Epoch: 073, Train Loss: 0.000004241, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 074, Train Loss: 0.000004187, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 075, Train Loss: 0.000004135, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 076, Train Loss: 0.000004083, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 077, Train Loss: 0.000004031, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 078, Train Loss: 0.000003979, Train Acc: 1.0000000, Test Acc: 0.7150000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 079, Train Loss: 0.000003928, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 080, Train Loss: 0.000003878, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.054\n",
            "=============iteracao0==================================\n",
            "Epoch: 081, Train Loss: 0.000003828, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.047\n",
            "=============iteracao0==================================\n",
            "Epoch: 082, Train Loss: 0.000003779, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 083, Train Loss: 0.000003731, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 084, Train Loss: 0.000003683, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 085, Train Loss: 0.000003637, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 086, Train Loss: 0.000003590, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 087, Train Loss: 0.000003544, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.049\n",
            "=============iteracao0==================================\n",
            "Epoch: 088, Train Loss: 0.000003500, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 089, Train Loss: 0.000003455, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 090, Train Loss: 0.000003413, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 091, Train Loss: 0.000003370, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 092, Train Loss: 0.000003329, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 093, Train Loss: 0.000003289, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 094, Train Loss: 0.000003249, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.050\n",
            "=============iteracao0==================================\n",
            "Epoch: 095, Train Loss: 0.000003211, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 096, Train Loss: 0.000003173, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 097, Train Loss: 0.000003135, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "=============iteracao0==================================\n",
            "Epoch: 098, Train Loss: 0.000003098, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.047\n",
            "=============iteracao0==================================\n",
            "Epoch: 099, Train Loss: 0.000003062, Train Acc: 1.0000000, Test Acc: 0.7160000, Time:0.048\n",
            "Tempo total:5.103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1yE8_rNvIK8"
      },
      "source": [
        "acc_total_test = np.array(acc_total_test,dtype='float64')\n",
        "acc_total_train = np.array(acc_total_train,dtype='float64')\n",
        "\n",
        "train_cross_entropy_var = torch.var_mean(torch.from_numpy(acc_total_train),True)[0].item()\n",
        "train_cross_entropy_mean = torch.var_mean(torch.from_numpy(acc_total_train),True)[1].item()\n",
        "\n",
        "\n",
        "test_cross_entropy_var = torch.var_mean(torch.from_numpy(acc_total_test),True)[0].item()\n",
        "test_cross_entropy_mean = torch.var_mean(torch.from_numpy(acc_total_test),True)[1].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot_6RDhsu0Ml"
      },
      "source": [
        "print(f'acc_train_total_variance:{train_cross_entropy_var:.4f} \\nacc_train_total mean:{train_cross_entropy_mean:.3f}')\n",
        "print(f'acc_test_total_variance:{test_cross_entropy_var:.4f} \\nacc_test_total mean:{test_cross_entropy_mean:.3f}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVH-eXsHCx46"
      },
      "source": [
        "<h4><center>Training - Random Split do dataset</center></h4>\n",
        "Cora: <br >\n",
        "train_mask = tensor(140, device='cuda:0'), <br >\n",
        "val_mask = tensor(500, device='cuda:0'),    <br >\n",
        "test_mask = tensor(1000, device='cuda:0')) <br >\n",
        "\n",
        "Citeseer: <br>\n",
        "train_mask = (tensor(120, device='cuda:0'),<br >\n",
        "val_mask = tensor(500, device='cuda:0'),   <br >\n",
        "test_mask = tensor(1000, device='cuda:0')) <br >\n",
        "\n",
        "pubmed: <br >\n",
        "(tensor(60, device='cuda:0'),<br >\n",
        " tensor(500, device='cuda:0'),<br >\n",
        " tensor(1000, device='cuda:0'))<br >\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Loss Function</th>\n",
        "    <th>Cora</th>\n",
        "    <th>Citeseer</th>\n",
        "    <th>Pubmed</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Cross Entropy</td>\n",
        "    <td>76,3% ± 0.0002</td>\n",
        "    <td>56,2% ± 0.0008 </td>\n",
        "    <td>74,3% ± 0.0001</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Hinge Loss Multiclass</td>\n",
        "    <td>78,0% ± 0.0004</td>\n",
        "    <td> 55,6% ± 0.0003</td>\n",
        "    <td> </td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbKvSE_eq-FP"
      },
      "source": [
        "\n",
        "plt.plot(loss,'r')\n",
        "plt.plot(loss_ce)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLzKjou9oCaM"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}